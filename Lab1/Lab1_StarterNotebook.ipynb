{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1: Starter Notebook\n",
    "#### Testing that your OpenAI API key is set up correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install OpenAI Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is if you have not installed OpenAI Python Library. Move to next cell if installed.\n",
    "# Install or upgrade the OpenAI Python library\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Verify Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.10\n",
      "openai 1.52.0\n"
     ]
    }
   ],
   "source": [
    "# Verify Python version\n",
    "!python --version\n",
    "\n",
    "# Verify OpenAI library version\n",
    "!openai --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Ensure OpenAI Key Is Correctly Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Retrieve the API key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Printing OpenAI API Key.\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat 1: Single-Turn Chat Completion with GPT-3.5 Turbo (Expert Role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are a type of deep learning model that has gained popularity in various natural language processing (NLP) tasks due to their ability to capture long-range dependencies in sequences of data, such as sentences or documents. Transformers were introduced in the landmark paper \"Attention is All You Need\" by Vaswani et al. in 2017.\n",
      "\n",
      "The key innovation of transformers is the self-attention mechanism, which allows the model to weigh the importance of different input tokens when processing each token in parallel. This mechanism enables transformers to capture complex patterns and relationships in the input data, making them highly effective for tasks requiring a deep understanding of language, such as machine translation, text generation, and sentiment analysis.\n",
      "\n",
      "Transformers consist of multiple layers of self-attention and feed-forward neural networks, which are stacked hierarchically. Each layer processes the input data independently and passes its output to the next layer. The model learns to adjust the attention weights during training to focus on relevant parts of the input sequence and ignore irrelevant information.\n",
      "\n",
      "One of the most well-known transformer architectures is the Transformer model proposed by OpenAI, which includes variants like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer). These models have achieved state-of-the-art results on a wide range of NLP tasks and are widely used in both research and industry.\n",
      "\n",
      "Overall, transformers have revolutionized the field of NLP by providing powerful tools for processing and understanding large amounts of text data, and their flexible architecture has also led to their application in diverse domains beyond NLP, such as computer vision, speech recognition, and reinforcement learning.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Initialize the OpenAI client with the API key from the environment\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create a chat completion request\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a expert in Machine Learning.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain the concept of transformers in machine learning.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat 1: Analysis\n",
    "\n",
    "This example demonstrates a **single-turn interaction** between the user and the assistant. Unlike the multi-turn approach, this style involves a single prompt from the user and a single response from the assistant.\n",
    "\n",
    "- The system message sets the assistant to behave as an **expert in Machine Learning**, which influences the style and tone of the response.\n",
    "- The user then asks the assistant to explain the concept of transformers in machine learning.\n",
    "\n",
    "In this type of interaction, the assistant processes the input and responds immediately, without retaining any context for follow-up questions. \n",
    "\n",
    "Single-turn interactions are useful when we need a **direct answer** to a specific question and there is no need for further dialogue or continuity between the responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat 2: Multi-Turn Chat Completion with GPT-3.5 Turbo (Contextual Interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In transformers, attention is a mechanism that allows the model to focus on different parts of the input sequence when processing it. It helps the model weigh the importance of each input token relative to the others. This allows the model to capture long-range dependencies in the input sequence and improves its performance on tasks like language translation and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Initialize the OpenAI client with the API key from the environment\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "# Create a chat completion request with more interaction\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain the concept of transformers in machine learning.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Transformers are a type of model architecture in machine learning used for tasks like natural language processing.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you explain how attention works in transformers?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat 2: Analysis\n",
    "\n",
    "In this example, we are simulating a **multi-turn conversation** between the user and the assistant. The assistant is prompted with multiple messages, including follow-up questions. \n",
    "\n",
    "- The system message instructs the assistant to be a **helpful assistant**, which sets the tone for the interaction.\n",
    "- The assistant is first asked to explain the concept of transformers in machine learning.\n",
    "- Then, the assistant is given a hardcoded response, which is useful to simulate prior knowledge in the conversation.\n",
    "- Finally, a **follow-up question** is asked about attention mechanisms in transformers.\n",
    "\n",
    "This interaction style is useful when we want the assistant to maintain **context** across multiple user inputs and provide more cohesive answers that build on previous responses.\n",
    "\n",
    "The assistant has access to **all previous interactions**, so it can generate more nuanced and coherent answers that align with the ongoing conversation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAILAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
